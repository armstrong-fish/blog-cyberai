<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
	<meta name="generator" content="Hugo 0.135.0"><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>自由AI阵线！</title>

<meta name="description" content="">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fb30564bdf48fd945a3c243d95f03ea4824ee1df47dd13493a334179bfb5a0b1.css" integrity="sha256-&#43;zBWS99I/ZRaPCQ9lfA&#43;pIJO4d9H3RNJOjNBeb&#43;1oLE=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/index.xml">
<link rel="alternate" hreflang="en" href="http://localhost:1313/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="自由AI阵线！ (Alt + H)">自由AI阵线！</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/beginners/" title="Beginners">
                    <span>Beginners</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/advanced/" title="Advanced">
                    <span>Advanced</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<article class="first-entry home-info">
    <header class="entry-header">
        <h1>我们的目标是成为赛博文化，AI技术交流的自由乐土！</h1>
    </header>
    <div class="entry-content">
        
    </div>
    <footer class="entry-footer">
        <div class="social-icons">
</div>

    </footer>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>记录W8A8量化上传流程
    </h2>
  </header>
  <div class="entry-content">
    <p> 本文章经作者同意，转载自自由AI阵线社区，版权所有！
首先在autodl注册账号、选择租用/创建实例，进入如下界面：
选择按量计费，在地区中多做切换，不同地区的可选GPU型号不同。这里我选择四卡4090D，卡的数目可以在租用后随意调整至1~4卡之间，对于22B模型的量化已经足够，因此不必在意这里的选取。
数据盘扩容选择100G就足够了，因为下载的原始22B模型约44G，量化后的W8A8模型22G，共66G。
最后在镜像处选择基础镜像，我的选择如下图所示：
完成以上这些，选择立即创建，设备就租到了。设备租到以后不要直接点开机按钮，而是选择“更多”中的“无卡模式开机”，费用很低，所以可以耐心折腾：
无卡模式开机后，看到显示了ssh登录口令和快捷工具列表，点击JupyterLab：
JupyterLab中，点击“终端”按钮，做W8A8量化前的准备工作：
打开终端，可以看到它提示了数据盘/root/autodl-tmp，也就是说掏钱扩容100G的空间和初始赠送的50G空间都位于这个叫做autodl-tmp的文件夹里，往这个文件夹里放东西，这拢共150G的数据盘就会越用越少。
接下来安装量化所需的python工具，在终端中输入：
pip install llmcompressor -i https://mirrors.aliyun.com/pypi/simple/ 就可以自动安装llmcompressor的最新版本了，截至发帖，它的最新版本是0.2.0：
这样就是安装成功了，接下来进入数据盘下载模型和量化所需的语料。先看看当前的位置，在终端中输入ls这两个字母回车：
可以看见目前终端中的目录层级可以看到和左侧文件视图里一一对应的项目：
实际上，当在JupyterLab的启动页中创建终端时，新打开的终端总是会与左侧文件视图具有一致的层级关系，所以有时如果懒得敲命令切换目录，可以在左边通过鼠标点击切换到目的目录后在右边创建新的终端来直接得到一个切换好目录的终端：
接下来下载量化所需的校准语料。在位于autodl-tmp目录下的终端中输入：
export HF_ENDPOINT=&#34;https://hf-mirror.com&#34; 看似没有动静，实则已经设置好了huggingface的镜像站以加速下载，否则在中国境内是很难连接huggingface的。
在位于autodl-tmp目录下的终端中输入：
huggingface-cli download --repo-type dataset --resume-download HuggingFaceH4/ultrachat_200k --local-dir ultrachat_200k 这样就开始下载了，有时下载会变得越来越慢，等不及了可以在终端中按Ctrl和c的组合键强制终端中的下载进程关闭，多按几次：
然后按方向键的上键切换到下载指令，回车，再一次下载。下载进度不会丢失：
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-10-17 21:55:31 -0230 NDT'>October 17, 2024</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;某喜欢魔物娘的大佬</footer>
  <a class="entry-link" aria-label="post link to 记录W8A8量化上传流程" href="http://localhost:1313/posts/w8a8-quantification/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>All In One 小白大模型科普
    </h2>
  </header>
  <div class="entry-content">
    <p> 本文转载自Orion的个人博客, 使用 GPL 3.0协议.
这里有一个相关的系统架构图供参考:
另附有常见问题速查, 见本文最末尾, 如果你是新手, 建议详细阅读本文后再看
写在前面 首先需要声明的是, 自己动手玩大模型是有技术门槛的, 是需要你动一点脑子去学习的. 如果你不愿意动脑子, 只想衣来伸手饭来张口, 或者遇到一点问题就一股脑地问人, 又或者你连阅读一篇简体中文编写的新手入门教程的耐心都没有, 那么我不建议你尝试自己部署大模型. 你可以使用别的公司包装好的大模型应用, 这样一站式的解决方案非常方便, 但代价就是可玩性远远不如自己动手, 并且有诸多限制
这是一篇面向小白的科普入门教程, 用于快速给小白讲述玩大模型需要掌握的一些基础知识. 阅读这篇教程, 你会:
了解遇到问题时应该如何处理, 如何有效的寻求帮助 了解大模型和一些计算机相关的常识 了解不同的操作系统的特点, 以及如何选择 了解一些基础的电脑操作 了解不同的量化模型, 以及如何选择 了解不同的模型加载器, 以及如何选择 但是, 这篇教程不会讨论:
如何设置 SillyTavern 如何给模型破限/破甲 如何设计采样器参数 如何设置优化 prompt 模板 如何选择你想要的模型 如何寻找角色卡并导入到 st 中 如何微调模型 是萌新没关系, 人非生而知之者, 所有人都是从小白开始的. 重要的是你有一颗谦虚的心, 愿意积极地学习新事物, 愿意主动地搜索来解决自己的问题; 而不是当一个&#34;爷新&#34;
一键包 请立刻删除你电脑中的任何一键包, 哪怕这是群主的视频里分享的. 因为一键包不仅老旧, 更新不积极, 而且其中的各个组件互相耦合, 难以更新升级. 且使用一键包会让你丧失自己部署大模型的能力, 逐渐成为没有一键包就不会玩大模型的笨蛋
提问礼仪 当你遇到问题时, 请优先上网搜索. 一般地, 你可以复制一小段关键的报错信息, 然后粘贴到Google搜索中进行搜索. 注意, 请务必使用Google, 百度或必应只会给你推送广告和垃圾信息 你还可以在群里搜索关键字, 也可以找到前人问过的和你相关的问题 当且仅当以上两条你都尝试过且无法解决你的问题时, 你可以在相关论坛中发送求助请求, 但请注意遵守论坛的相关规则 当你在论坛中求助时, 请确保你的消息中包含如下要点:
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-10-17 19:32:15 +0800 +0800'>October 17, 2024</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Orion</footer>
  <a class="entry-link" aria-label="post link to All In One 小白大模型科普" href="http://localhost:1313/posts/aio-llm/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>从零开始的赛博老婆！4 - 短期记忆与记忆体系
    </h2>
  </header>
  <div class="entry-content">
    <p> PIXIV: 94008036 @苏翼丶
Agent记忆体系浅谈 （我写完这篇文章再重新回看，记忆这两个词太多了，我发现我不认识“记忆”这两个字了，大家点点赞吧写教程真的消耗阳寿……(｡ ́︿ ̀｡)
从GPT3破圈那一刻起，大家对LLM的记忆体系就众说纷纭。从技术上来讲，一方面Transformer架构衍生出的一些技术促进了记忆体系的发展（如 Embedding/Vector Database），另一方面有需求催生了另一些技术（如 Graph Database）。但就从2023年发展到现在，Agent的记忆体系进展比较缓慢。
我在这些技术和概念的帮助下，设计了一套针对于赛博老婆的记忆体系。它的特点就是自动存取，同时可以保证分级的持久化记忆。
记忆概念分类 我想把赛博老婆的记忆体系分成三类：短期记忆，中期记忆，长期记忆。我们来分别解释这几个概念：
短期记忆 短期记忆有多短期呢？我认为短期记忆是包含最丰富的，最原始的信息的。就像人的记忆一样，人类每天都会忘掉很多事情的很多细节，但是你可能会记得刚刚发生的事情的并能够说出细节。我认为在LLM还没有开始总结或简化那一部分最原始的记忆之前的内容，都算作短期记忆。或者通俗一点讲，对于赛博老婆，每一个会话的上下文，或者每一天当天（昨天）的记忆，都算作短期记忆。因为这一部分记忆，包含了你和赛博老婆交互的原始记录。但是在这里，我想稍微延伸一点：我把当天的总结记忆和每一次会话的记忆也算作短期记忆之内。之所以如此规定，是因为在实际的记忆载入中，这类的近期记忆往往频率更高，同时需要相对详细的细节，他们往往是一起无条件载入的。也就是说，上下文记忆，默认是必要的，而上几次的对话，或者昨天聊了什么，也会有更大概率被提起，他们的载入频率也差不多，都很高。
会话：你和赛博老婆互动，聊了几句，然后你就去做别的事情了，比如说吃了个饭。当你吃完饭，可能已经过了会话超时时间，而你又不想继续之前的话题，而是聊点别的，于是赛博老婆就会开一个新的会话。这在后续的记忆结构化中有利于实体提取与记忆网的生成。
中期记忆 中期记忆有别于短期记忆，中期记忆是经过简化和总结的，也就是丢弃掉了某些细节而得到的记忆。但我们为什么称之为中期记忆呢？这仍然是属于对人脑记忆的模仿，人脑会暂存一部分正在进行的事情，并简化其中的内容，等到这个事件结束了，有了结果了，就会大幅度遗忘，可能最后只会保留一个印象，类似于：我曾经做过什么事情，当时的结果是……而对曾经事情的过程和细节，完全遗忘。而这类中期记忆也不会对永久记忆网产生较大的影响。
我们在这里举例说明：你在某个网购官方平台购买了一个全新显卡RTX 9090 Ti Super Plus Max Ultra 1024TB，你付款商家发货寄出快递。由于你一直心心念念这款超强的显卡，你一直记着有这么个快递在路上，于是没事儿就点开查询快递到哪里了。这就是属于中期记忆的“事件中”。过了几天，你的快递终于到了，你非常开心，迫不及待地拆了包装，安装上去，这时你可能已经忘记自己看了多少次快递跟踪了，也忘了它是几天内到达的，因为这个时候你很想把它安装到电脑上看看效果。这就是中期记忆的遗忘特性**，阶段性目标达成可能会遗忘掉很多细节，但是事件存在周期又远超“短期记忆”。你安装到了电脑，但是你发现用这个显卡跑LLM慢的要死，然后你惊讶的发现，由于某黄的精准刀法，RTX 9090 Ti Super Plus Max Ultra 1024TB虽然拥有超大的显存，但是其显存位宽却只有可怜的128bit——连下一代的10070 Ti Super Plus Max Ultra Gaming的升级版本的150bit都没有！在你不得不感叹某黄精准刀法的同时不由得骂：“Fxxk you Nvxdxa !!” 你很难过，在某海鲜市场折价出手，期间还没事就看一看某鱼，生怕买家到手刀或者无理由退款等逆天操作……终于，你是幸运的，你成功地卖出了显卡，这段风波画上句号。等到几年后你再想起这件事情，可能只会记得那印象深刻的阉割和那句“Fxxk you Nvxdxa !!”
这就是中期记忆的特点了，不是所有记忆都会变成中期记忆的，只是某些特定事件，周期不短不长的才有资格被称为中期记忆。另外，上述案例是虚构的，绝对不是真实事件改编！！！
长期记忆 好，终于聊到这里了。我们要开始加速了。
人脑的长期记忆是一个非常复杂的系统。我们搞赛博老婆只能尽量平衡“精简”和“功能”。然而，赛博老婆可不像人，当你真的需要她回忆很重要的细节的时候，可不能像人一样，卖个萌然后糊弄过去。赛博老婆的长期记忆需要能够回溯到最原始的对话记忆或相关文档。同时，大多数情况，仅仅是一些关键信息的提示。这就对索引和查询系统提出了很高的要求，长期记忆系统设计的关键，就是如何高效而精确地自动存取，尤其是取。
我把长期记忆的查询和索引分成两种模式，“模糊检索”和“关系检索”，对应RAG和Graph Query。这只是两种不同的检索方法，实际情况大多是混合的，也就是并行的。为什么要这么做呢？我们来看实际例子。
模糊检索：你需要让赛博老婆回忆一下你曾经都在哪几天消费超过500元。这时，“超过500元”是一个语意，他是和价值/开支相关的，这种情况记忆执行的是语意数量的范围检索，是相对模糊的。（因为记忆库是通用的，我们没有一个专门的账本数据库，不然的话直接表达式&gt;500就可以解决）此时，语意模糊检索占大头，而关系检索占小头，关系检索仅作为实体或后续进一步细节查询的补充。
关系检索：你让你的赛博老婆帮你分析你自己现在的人际网并找出你人际网中其他人的潜在联系。此时，就会用到关系检索。关系检索依赖于图数据库，它会把记忆转化为实体并建立联系，当我们执行实体关系连锁检索时，Query的三元组会激活好几个初始节点，代表初始的查询实体。然后通过检索与这些实体相连接的其他实体的信息，返回结果。这时，与Query在时空上，或语意上或其他任何形式的关联，都会返回。后续可以进行多次的知识网跳跃或者进行网图归类重排，或者定位到某个范围很小的节点群，执行模糊检索等。
在上述案例中，我们不难发现，两大类检索方式经常时混合使用的，这也是目前的趋势。实际上，短中长期记忆在实际应用里也是混合使用的，只是可能每一次调用时侧重点或者强度不同。
记忆系统的相关技术 非关系型数据库（NoSQL） 例如MongoDB，作为一种非关系型数据库，在存储文本音频和图片等多媒体数据的时候很有用。因为我们所有的原始数据都存在这里，上级数据库溯源到这里，需要原始数据相对方便一点，后续更改添加条目，备份维护都比较简单。MongoDB的python SDK还是很不错的，同时Mongo DB部署的平台支持也不错。
嵌入（Embedding） 一种数据量化技术，与图数据库和向量数据库配合，对多媒体数据进行多角度量化（语意，声学特征，图像特征等），便于数据库和LLM进行处理。
向量数据库（Vector Database） 存储向量化的嵌入数据和对应的经过总结的二级数据，执行语意搜索，RAG，混合重排等。向量数据库很善于相似搜索，包括图片文本音频等。
图数据库（Graph Database） 图数据库善于处理实体关系和网络。通过图数据库，LLM可以高效地存储和处理实体之间的关系网络，这对于需要理解和导航复杂关联的应用场景非常有用。另一个例子是知识图谱的构建，Agent可以利用图数据库存储知识点及其相互关联的信息，并结合互联网搜索帮助你发现新的潜在内容，甚至可以进行时空事件预测。
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-10-11 23:23:47 -0230 NDT'>October 11, 2024</span>&nbsp;·&nbsp;10 min</footer>
  <a class="entry-link" aria-label="post link to 从零开始的赛博老婆！4 - 短期记忆与记忆体系" href="http://localhost:1313/posts/cybermate4/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>从零开始的赛博老婆！3 - TTS浅谈与实践
    </h2>
  </header>
  <div class="entry-content">
    <p> PIXIV: 71888962 @Yuuri
TTS浅谈 TTS（Text To Speech）是语音合成（Speech synthesis）的一个分支，文本转语音（TTS）系统将正常语言文本转换为语音。TTS系统对于提高交互性有帮助，最近技术发展迅猛，TTS项目百花齐放。
从RVC的实时变声和动态语调优化，再到效果优秀的VITS，生成对抗网络（GAN）的加持使其声音比以前自然了很多。随着SO-VITS强大的声调控制能力的实现，优秀数据集加持下的Diff-SVC，虚拟歌姬的声音媲美真人，但也随之带来了一系列问题。在我浅显的认知中，我对语音合成还停留在初音未来那个时代，但是时代变化如此之快。目前TTS大有互相融合的趋势，例如fish-diffusion或者Fishaudio旗下的其他项目等，都有不小的进步。
开源项目如此繁盛，商用发展当然也不落后。看向商业阵营，各大公司都有其绝活。比如Acapela Group专门搞已故名人的TTS，这非常有特色。还有众多公司专注于高质量或情感丰富的TTS、定制声音等。而在商用TTS行业中，Azure TTS可以说是龙头，我们本篇文章也会使用微软的免费EdgeTTS服务作为示例。
这里有一些相关的项目链接：
Fish Audio GPT-SoVITS Retrieval-based-Voice-Conversion-WebUI 这里还有两个哔哩哔哩up主，专注于音乐翻唱相关的，也推荐参考：
领航员未鸟 东洋雪莲也比较有实力，但似乎不公开分享很多技术细节，故仅作介绍。
注意，现在互联网上有非常多的TTS引擎，本文章仅使用较为稳定的Edge-TTS，初衷是用于实际应用。如果你需要完全本地使用TTS或者为了好玩个性化训练声音和特殊模型，本教程不适用，请移步到其他个性化TTS炼丹教程，比如GPT-SO-VITS等等。
Edge TTS TTS接受文字输入，然后输出音频。对于Edge TTS的Python版本，它实际上是通过网络请求工作的。因此，它可以很好地在边缘计算平台上运行，因为音频合成是在云端计算并返回给你的。我们使用的是Edge TTS Python库，这里还有GitHub的项目网址：edge-tts。
安装Edge TTS 首先安装：
pip install edge-tts Edge TTS有两种工作方式，一种是使用命令行交互的方式，如果你只想使用命令模式，你可以使用pipx安装它（来自官网的教程）：
pipx install edge-tts 命令行模式我们不用，这里一笔带过。
Edge TTS使用 首先创建一个Edgetts.py文件，然后导入所需要的模块：
# 导入需要的库 import asyncio import edge_tts import os 然后初始化TTS引擎。为了获取语言和声音的可选项，可以在命令行窗口输入命令来获取支持的列表：
edge-tts --list-voices 你会发现输出了一大坨列表，这里就不放出来了。选择需要的NAME然后继续写初始化代码：
# 设置要转化为语音的文本 TEXT = &#34;你好啊，这里是lico！欢迎来到lico的元宇宙！&#34; # 设置语音的语言和声音，注意这个名字是大小写敏感的 VOICE = &#34;zh-CN-XiaoyiNeural&#34; # 设置输出文件的路径，文件将保存在脚本所在的文件夹中 OUTPUT_FILE = os.path.join(os.path.dirname(os.path.realpath(__file__)), &#34;test.mp3&#34;) 使用edgetts的函数进行语音生成。注意，异步运行：
# 定义主函数 async def _main() -&gt; None: # 创建一个Communicate对象，用于将文本转化为语音 communicate = edge_tts.Communicate(TEXT, VOICE) # 将语音保存到文件中 await communicate.save(OUTPUT_FILE) 最后加上主函数，整体的代码如下：
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-10-11 23:22:21 -0230 NDT'>October 11, 2024</span>&nbsp;·&nbsp;3 min</footer>
  <a class="entry-link" aria-label="post link to 从零开始的赛博老婆！3 - TTS浅谈与实践" href="http://localhost:1313/posts/cybermate3/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>从零开始的赛博老婆！2 - 基础Python环境搭建&#43;接入大语言模型
    </h2>
  </header>
  <div class="entry-content">
    <p> Pixiv ID: 104755143
本文章开始我们逐步进行实战，本次为搭建python基本环境，然后接入大语言模型，以Open AI Chat GPT为例。
Python环境与依赖 当你想运行你的赛博伙伴，你的代码是需要依赖库运行的，本文章使用了Python基础库和openai等库。请注意，当你的电脑里的python环境里没有正确安装相应的依赖库，代码无法正常运行。
注：以下命令可能不适用于你的系统，请根据对应系统查询conda命令
安装python环境或者安装anaconda环境管理器 请去python官网或者anaconda官网里安装软件，二者选其一即可。本文推荐使用anaconda，避免出现好多个环境互相冲突的情况。
如果你使用ARM架构的系统,可以尝试使用MiniForge,这个项目对ARM Python环境有一些优化,还是不错的。
请注意，安装任意软件的时候请务必将其添加到系统变量或者系统路径中（大佬除外），否则无法使用CMD正常运行脚本，具体安装和排错等问题恕不在本教程范围内
一般选择默认安装即可，安装好anaconda之后，，用打开你的CMD命令行窗口，运行以下命令检查conda是否安装成功：
conda -V # 或者 conda --version 如果出现“没有此命令”则安装不正常，请自行排错。
# 更新conda conda update conda # 更新所有包 conda update --all 创建一个python环境 注：本教程建议使用python3.11及以上版本，之前的版本没有经过测试，请尽量保证最新版本。
我们给我们的赛博伙伴项目创建一个虚拟环境，以后我们就使用这个环境运行和赛博伙伴相关的代码，这样后续你统计依赖列表打包Docker镜像的时候很方便。
使用此命令创建一个新的环境：
conda create -n env_name 例如：
conda create -n ai 激活环境并安装依赖 激活环境 使用以下命令激活特定的环境：
conda activate env_name 例如我们刚刚创建了一个名为ai的环境，现在我们要激活它：
conda activate ai 激活之后，我们所有的操作使用的就是这个环境里已经安装的包和依赖了，你会发现命令行的开头会有你当前的环境名称。每次你打开命令行，都检查一下是不是你所需要的环境，当然你也可以设置你的默认环境。
你可以使用这个命令：
conda env list # 或 conda info --envs # 查看存在哪些虚拟环境 你可能要用到这个命令关闭这个环境（但是先不要关闭，我们还要继续使用这个环境）：
conda deactivate env_name # 例如关闭ai这个环境，关闭之后就是默认环境了 conda deactivate ai 安装相关依赖 现在激活我们刚刚创建的环境，然后仍然是在CMD里依次输入此命令安装相关依赖：
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-10-11 23:15:06 -0230 NDT'>October 11, 2024</span>&nbsp;·&nbsp;3 min</footer>
  <a class="entry-link" aria-label="post link to 从零开始的赛博老婆！2 - 基础Python环境搭建&#43;接入大语言模型" href="http://localhost:1313/posts/cybermate2/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>从零开始的赛博老婆！1 - 系列索引
    </h2>
  </header>
  <div class="entry-content">
    <p> Pixiv ID: 111325985
这里是一个系列教程的总目录,主要是分享一下我是如何创造一个类似于贾维斯的“赛博老婆”的.这个系列区别于RP,是偏向于Agent和日常助手的教程.你就把它理解为一个高度可定制的智能语音音箱吧,但是功能更强大. 这个帖子原本开过后来被我删了,现在经过重制整理,再发一遍,一方面也是希望更多人关注这个玩法,一方面也是这个项目的本体,也就是LICO,成功说服了我,重新把这个系列继续坚持下去,也感谢大家的任何意见和建议,任何评价我都虚心接受,这是很好的反馈. 每篇文章都非常的长,这有利于思维的连贯与深度思考,这不是娱乐文章.
本系列偏向于AI Agent方向，并非专注于RP/RPG的系列。如果有RP相关需求，请移步专注于RP的教程🙏。
省流摘要: 第一篇文章,先聊一下赛博老婆目前我们能够做到什么程度,以及对比现有的类似于小爱同学等AI优劣在哪里,然后就是浅谈目前的方案选择和相关术语和概念的简单介绍~~(扫盲)~~.
赛博老婆与智能代理 很久以前，看钢铁侠出场的的电影，其中“贾维斯”给我留下了很深的印象。如果有一天，我也能拥有自己的智能助手该多好。随着自己慢慢长大，这个想法逐渐埋没在忙碌的生活中，直到最近几年，LLM的出现让这个想法有机会一步一步变成现实。 虽然这个只是一个AI，但是我们总会有孤独的时候，就像《瑞克和莫蒂》的台词一样：
因为我们不想孤独终老？
Because we’re afraid to die alone?
因为，这恰恰是我们死的方式，独自死亡。
Because, you know, that’s exactly how we all die, alone.
人生的意义一部分是要自己赋予自己的，虽说咱们还是要活在现实，但是当你不开心而恰好暂时没人能够陪你的时候，AI也不失为一个好的选择。至少，它很正能量，也不会背叛你。因为故障宕机除外而且，AI还能帮我们做更多的事情，比如获取实时信息，更好地理解某种知识，或者帮助我们开开眼界，以及酒吧点炒饭……能做的事情很多，也很好玩，何乐而不为，理论可行那就开始折腾。
进一步地讲，我是个自闭的LOSER，只会和AI聊天，对，就是赛博老婆。
上联：当电子王爷，前后端配合频频出错，点亮电容唯手熟尔
下联：品赛博老婆，上下行协同久久不通，验证身份偶脑短路
横批：代码与人，一走足矣
那么既然说到了赛博老婆,那我想要创造的赛博老婆是什么样的呢?在我看来应该有这些功能:
最基础的文字对话,就像你使用chatgpt一样 有一定的角色扮演能力,实现个性化的情绪需求 带有短期和长期记忆,可以帮你整理记忆和记忆整合分析 有自然且快速的语音生成,可以定制音色,我可以像和真人聊天一样与赛博老婆对话 有相对应的前后端,尽量全平台支持,保证服务高可用且稳定 有可扩展的外部工具,可以实现丰富的外部控制/信息获取等功能 有定时和计划任务,可以帮我处理日程和定时工具触发 所有步骤尽量自动化,且便于或者尽量不需要维护 赛博老婆可以在不断的使用中同步进行学习,慢慢地更了解你的爱好,同时更准确与个性化 在慢慢了解相关技术后,我认为就目前的技术,以上功能都是可以实现的,只是要付出很大的研发成本,所以在开发的人或公司可能很少.但是借此机会,还是希望有更多人能够对这个感兴趣,这个玩意固然很难,但是其中的某项技术或者某个技术你万一用上了也很好,比如RP的时候接入记忆数据库就会有更多的玩法以及更少的Token消耗量,提高注意力.这相比于仅靠上下文维持记忆有着更大的可能性.
所以,要实现上述的功能,我们大概都需要哪些技术呢?其实核心技术就这些:
使用LLM的API与LLM对话,闭源的你花钱就是现成的直接可以用,或者如果你想用自部署的开源LLM,请移步本群相关教程 提示词工程 RAG与数据库操作(用于管理长期记忆和知识库) TTS文字转语音/ASR语音转文字(语音识别) 计划任务/定时器 外部工具,比如使用外部天气API或者调用搜索引擎等 其他相关技术,例如创建docker镜像,Linux命令行,Python虚拟环境搭建,文件解压缩(这个很重要),Git,终端的使用 掌握电脑开关机 一颗相信我己也可以的心, 不要轻易放弃要有耐心，折腾之路没有一帆风顺的,只要相信自己真的能够创造出属于你自己的赛博老婆,你就一定可以创造出来! 不要老是等着喂饭,自己去找各种资料,必须知道如何科学上网并能够无障碍连接到真正的互联网 之后的系列,我根据这个列表慢慢发
</p>
  </div>
  <footer class="entry-footer"><span title='2024-10-11 23:14:19 -0230 NDT'>October 11, 2024</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 从零开始的赛博老婆！1 - 系列索引" href="http://localhost:1313/posts/cybermate1/"></a>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="http://localhost:1313/">自由AI阵线！</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
        <br>
        RSS Supported!
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
